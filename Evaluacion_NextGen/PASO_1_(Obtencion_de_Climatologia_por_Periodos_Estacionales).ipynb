{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb85e31",
   "metadata": {},
   "source": [
    "En este código se realiza lo siguiente:\n",
    "\n",
    "01. Se importa la base de datos meteorológicos proporcionada por Insivumeh\n",
    "02. Desechamos todas las variables excepto la precipitación\n",
    "03. Rellenamos valores faltantes de precipitación por lo que indican la base de datos de ENACTS, cuyos datos son importados en un archivo en formato NetCDF de nombre precipitacion.nc\n",
    "04. Se calcula el acumulado por estaciones para cada estación meteorológica (las estaciones son DEFM, MJJ, ASO)\n",
    "05. Se calcula la media y los percentiles 1/3 y 2/3, así como la desviación estándar del conjunto de precipitación acumuladas de cada perído estacional para la Climatología (1991-2020). Este proceso se realiza para cada una de las estaciones meteorológicas.\n",
    "06. Se exporta un archivo de Excel que se incluya el nombre de la estación, el período estacional, y la media y los percentiles 1/3 y 2/3 del conjunto de precipitaciones acumuladas en la Climatología."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ccbbd6",
   "metadata": {},
   "source": [
    "# IMPORTACIÓN DE DATOS Y LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6fa5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'BaseDatos.xlsx'\n",
    "Datos = pd.read_excel(file_path)\n",
    "\n",
    "print(Datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e35192",
   "metadata": {},
   "source": [
    "# ELIMINACIÓN DE TODAS LAS VARIABLES EXCEPTO PRECIPITACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ee140",
   "metadata": {},
   "outputs": [],
   "source": [
    "VarEliminar = ['Humedad_R', 'Tmin', 'Tmax', 'Tmed', 'Radiacion','Brillo_Solar','Evap_Tanque','Presion_atms', 'Piche', 'Vel_viento', 'Dir_viento']\n",
    "\n",
    "Datos.drop(columns=VarEliminar, inplace=True)\n",
    "\n",
    "print(Datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc07a2",
   "metadata": {},
   "source": [
    "# AGREGAR DÍAS NO REGISTRADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470a877",
   "metadata": {},
   "source": [
    "EN PRIMER LUGAR, SE DEBE GENERAR UN REGISTRO DE LOS DÍAS QUE NO ESTÁN INGRESADOS, PARA CADA UNA DE LAS ESTACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame que contenga todas las fechas posibles en el rango de fechas para cada estación\n",
    "start_date = Datos['FECHA'].min()\n",
    "end_date = Datos['FECHA'].max()\n",
    "all_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Crear una lista para almacenar los resultados\n",
    "missing_dates = []\n",
    "\n",
    "# Iterar sobre cada estación\n",
    "for estacion in Datos['ESTACIÓN'].unique():\n",
    "    # Filtrar los datos por estación\n",
    "    Datos_estacion = Datos[Datos['ESTACIÓN'] == estacion]\n",
    "    \n",
    "    # Obtener las fechas presentes en la base de datos para esta estación\n",
    "    fechas_present = Datos_estacion['FECHA']\n",
    "    \n",
    "    # Obtener las fechas faltantes para esta estación\n",
    "    fechas_missing = all_dates.difference(fechas_present)\n",
    "    \n",
    "    # Agregar las fechas faltantes a la lista de resultados\n",
    "    for date in fechas_missing:\n",
    "        missing_dates.append({'ESTACIÓN': estacion, 'FECHA': date})\n",
    "\n",
    "# Convertir la lista de resultados a un DataFrame\n",
    "missing_dates_Datos = pd.DataFrame(missing_dates)\n",
    "\n",
    "print(\"Las fechas no ingresadas en la base de datos son: \")\n",
    "print(missing_dates_Datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd45ae",
   "metadata": {},
   "source": [
    "A CONTINUACIÓN, SE AGREGAN A LA BASE DE DATOS LOS DÍAS NO INGRESADOS; TODOS LOS VALORES DE ESTOS DÍAS APARECERAN VACÍOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ec12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir las columnas de datos meteorológicos con valores NaN\n",
    "for col in Datos.columns:\n",
    "    if col not in ['ESTACIÓN', 'FECHA']:\n",
    "        missing_dates_Datos[col] = np.nan\n",
    "\n",
    "# Combinar el DataFrame original con el DataFrame de fechas faltantes\n",
    "Datos = pd.concat([Datos, missing_dates_Datos], ignore_index=True)\n",
    "\n",
    "# Ordenar el DataFrame resultante por estación y fecha\n",
    "Datos = Datos.sort_values(by=['ESTACIÓN', 'FECHA'])\n",
    "\n",
    "print(Datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae38ec2",
   "metadata": {},
   "source": [
    "# AGRAGAR LAT, LON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b62f57",
   "metadata": {},
   "source": [
    "Se agregan estos datos como columnas adicionales a la base de datos, ya que serán útiles al realizar el rellenado de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d047b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la base de datos que contiene los nombres de las estaciones y su latitud, longitud y altura.\n",
    "file_path = 'Datos_estaciones.xlsx'\n",
    "Datos_estaciones = pd.read_excel(file_path)\n",
    "\n",
    "# Fusionar la base de datos con los datos de las estaciones, en función del nombre de la estación\n",
    "Datos = pd.merge(Datos, Datos_estaciones, on='ESTACIÓN', how='left')\n",
    "\n",
    "# Eliminar las columnas que, para nuestro caso, son irrelevantes\n",
    "VarEliminar = ['Altitud', 'Departamento', 'Municipio']\n",
    "Datos.drop(columns=VarEliminar, inplace=True)\n",
    "\n",
    "print(Datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el avance en un dataframe\n",
    "Preliminar1 = Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5548ce",
   "metadata": {},
   "source": [
    "# RELLENO DE DATOS FALTANTES DE PRECIPITACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb427125",
   "metadata": {},
   "source": [
    "SE SUSTITUYEN LOS DATOS FALTANTES POR LOS QUE INDICA LA BASE DE DATOS DE ENACTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar cuántos valores son desconocidos\n",
    "print(\"Valores vaciós de precipitación: \" + str(Datos['Lluvia'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac296c1-2403-48d0-aca4-4fc36bea722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "# Suprimir advertencias de tipo FutureWarning\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Crear una copia del DataFrame original, la cual se irá rellenando\n",
    "Datos_rellenados = Datos.copy()\n",
    "\n",
    "# Mapeo de variable de la base de datos a las variable en el archivo NetCDF (esto se hace ya que el nombre de la variable\n",
    "# en la base de datos meteorológicos puede no tener el mismo nombre que la variable en el archivo NetCDF)\n",
    "var_map = {\n",
    "    'Lluvia': 'rfe',\n",
    "}\n",
    "\n",
    "# Archivo NetCDF correspondiente\n",
    "nc_files = {\n",
    "    'rfe': 'precipitacion.nc',\n",
    "}\n",
    "\n",
    "# Cargar los archivos NetCDF en un diccionario\n",
    "nc_data = {var: xr.open_dataset(file) for var, file in nc_files.items()}\n",
    "\n",
    "# Iterar sobre las filas\n",
    "for i, row in Datos.iterrows():\n",
    "    # Extraer latitud, longitud y fecha para la fila actual\n",
    "    lat = row['Latitud']\n",
    "    lon = row['Longitud']\n",
    "    fecha = row['FECHA']\n",
    "    estacion = row['ESTACIÓN']\n",
    "    \n",
    "    # Iterar sobre las variables para la fila actual\n",
    "    for db_var, nc_var in var_map.items():\n",
    "        if pd.isna(row[db_var]):\n",
    "            # Extraer los datos de la variable correspondiente del archivo NetCDF\n",
    "            valor = nc_data[nc_var][nc_var].sel(\n",
    "                Y=lat, X=lon, T=fecha, method='nearest'\n",
    "            ).values\n",
    "            \n",
    "            # Reemplazar el valor en el DataFrame\n",
    "            Datos_rellenados.at[i, db_var] = valor\n",
    "            \n",
    "    print(\"Se han rellenado las variables en la estación \" + \"'\" + estacion + \"'\" + \" en la fecha \" + str(fecha))\n",
    "\n",
    "print(Datos_rellenados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizar el DataFrame original con los datos rellenados\n",
    "Datos = Datos_rellenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que no quede ningún valor vacío\n",
    "print(\"Valores vaciós de precipitación: \" + str(Datos['Lluvia'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente, guardamos el avance en un dataframe\n",
    "Preliminar2 = Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc91842",
   "metadata": {},
   "source": [
    "# GENERACIÓN DE DATOS DE LA CLIMATOLOGÍA POR PERÍODO ESTACIONAL PARA CADA UNA DE LAS ESTACIONES METEOROLÓGICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8044b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los períodos estacionales\n",
    "def obtener_periodo_estacional(mes):\n",
    "    if mes in [11, 12, 1]:\n",
    "        return 'DEFM'  # Diciembre, Enero, Febrero, Marzo\n",
    "    elif mes in [5, 6, 7]:\n",
    "        return 'MJJ'  # Mayo, Junio, Julio\n",
    "    elif mes in [8, 9, 10]:\n",
    "        return 'ASO'  # Agosto, Septiembre, Octubre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d1b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una columna de \"Período estacional\"\n",
    "Datos['Periodo_estacional'] = Datos['FECHA'].dt.month.apply(obtener_periodo_estacional)\n",
    "\n",
    "# Agregar una columna para el año\n",
    "Datos['Año'] = Datos['FECHA'].dt.year\n",
    "\n",
    "print(Datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos para la climatología que abarca de diciembre de 1990 hasta octubre de 2020\n",
    "Datos_climatologia = Datos[\n",
    "    ((Datos['Año'] == 1990) & (Datos['FECHA'].dt.month == 12)) |  # Desde diciembre 1990\n",
    "    ((Datos['Año'] > 1990) & (Datos['Año'] < 2020)) |  # Años completos entre 1992 y 2020\n",
    "    ((Datos['Año'] == 2020) & (Datos['FECHA'].dt.month <= 10))  # Hasta octubre 2020\n",
    "]\n",
    "\n",
    "print(Datos_climatologia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los datos por estación, año y período estacional y calcular el acumulado de precipitación\n",
    "acumulados = Datos_climatologia.groupby(['ESTACIÓN', 'Año', 'Periodo_estacional'])['Lluvia'].sum().reset_index()\n",
    "\n",
    "print(acumulados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9121e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, calcular la media, percentil 1/3 y 2/3 de los acumulados de cada estación y período estacional para los años de climatología\n",
    "estadisticos = acumulados.groupby(['ESTACIÓN', 'Periodo_estacional']).agg(\n",
    "    Media=('Lluvia', 'mean'),\n",
    "    Percentil_1_3=('Lluvia', lambda x: np.percentile(x, 33.333333333)),\n",
    "    Percentil_2_3=('Lluvia', lambda x: np.percentile(x, 66.666666666))\n",
    ").reset_index()\n",
    "\n",
    "print(estadisticos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar los resultados a un archivo Excel\n",
    "estadisticos.to_excel('Climatologia_por_Periodos_Estacionales.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2171fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
